---
title: HCAI Podcast Episode 13 - Human-centered AI with Ben Shneiderman
date: 2025-12-09
profile: false
type: podcast
image:
  preview_only: true
  focal_point: smart
  placement: 1

links: 
- icon: spotify
  icon_pack: fab
  name: Spotify
  url: https://open.spotify.com/episode/5E9bATCNNvUt5gt2wT7k9h?si=A-oL4gQLR6mSQh1xwVGryw
- icon: podcast
  icon_pack: fa
  name: Pocket Cast
  url: https://pca.st/r6ep4lkl
- icon: youtube
  icon_pack: fab
  name: YouTube
  url: https://www.youtube.com/watch?v=b6Qt9mLFNOQ
- icon: rss
  icon_pack: fa
  name: RSS
  url: https://anchor.fm/s/ed407214/podcast/rss

banner:
  image: podcast-header.jpg  

---


This episode’s guest is [Ben Shneiderman](https://www.cs.umd.edu/users/ben/), Professor Emeritus of Computer Science at the University of Maryland, co-founder of the Human-Computer Interaction Lab, and author of the book [Human-Centered AI](https://global.oup.com/academic/product/human-centered-ai-9780192845290). Shneiderman reflects on his pioneering career spanning direct manipulation, information visualization, and decades of advocacy for human-centered design. He traces his path from traditional computer science to a deep engagement with psychology and user interface design, and he explains why human-centered AI must focus on amplifying, augmenting, empowering, and enhancing human performance rather than creating anthropomorphic agents.

<!--more-->

In the conversation, Shneiderman discusses the long history of AI agents, why he believes agentic metaphors undermine user self-efficacy, and how visual, tool-like interfaces remain far more effective than conversational ones for most tasks. He examines the risks of anthropomorphized AI companions, including documented cases of harm, and emphasizes the need for clearer responsibility, stronger testing, incident reporting, and regulatory frameworks like the EU AI Act. He also comments on the limitations of concepts like alignment and trustworthiness, advocating instead for developing systems that are safer and more reliable rather than “safe” or “trustworthy” in absolute terms.

The discussion touches on the impact of generative AI on software development, the importance of preserving accountability even when tools generate code, and the ongoing relevance of HCI methods such as usability testing, controlled experiments, and careful rollout processes. Shneiderman argues that human-centered AI aligns naturally with fairness, accountability, and transparency, and he encourages students and practitioners to engage deeply with design principles, evaluation methods, and real-world team projects that produce meaningful, lasting systems.


<iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/5E9bATCNNvUt5gt2wT7k9h/video?utm_source=generator" width="100%" height="351" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

<!--iframe allow="autoplay *; encrypted-media *; fullscreen *; clipboard-write" frameborder="0" height="175" style="width:100%;overflow:hidden;border-radius:10px;" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation" src="https://creators.spotify.com/pod/show/hcai/embed/episodes/HCAI-12---Democratizing-AI-with-Mark-Coeckelbergh-e2sfsac/a-abmhv47"></iframe-->


<iframe width="100%" height="600" src="https://www.youtube.com/embed/b6Qt9mLFNOQ?si=A4Sf2Co1MfPGhr1D" title="HCAI 13 - Human-centered AI with Ben Shneiderman" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>



<img src="featured.png" width="200px">